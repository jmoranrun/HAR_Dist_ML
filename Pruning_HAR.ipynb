{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pruning_HAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "environment": {
      "name": "tf2-2-2-gpu.2-2.m50",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmoranrun/HAR_Dist_ML/blob/main/Pruning_HAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zt0JEl38SWX"
      },
      "source": [
        "#Pruning Experiments around Personalization for Human Actvity Recognition. \n",
        "I used the Karas Notebook \"Magnitude-based weight pruning with Keras\" as a reference.\n",
        "\n",
        "This notebook was used to run the experiments in the presentation:\n",
        "Human Activity Recognition in a Distributed Machine Learning System. Jul 26, 2021  IEEE International Conference on Wearable and Implantable Body Sensor Networks (BSN2021)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn836LSTNSHA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "30ca570c-e10c-4397-ee34-772a832fe33c"
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip uninstall -y tf-nightly\n",
        "#! pip install -U tensorflow-gpu==1.14.0\n",
        "! pip install -U tensorflow-gpu\n",
        "\n",
        "! pip install tensorflow-model-optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping tf-nightly as it is not installed.\u001b[0m\n",
            "Requirement already up-to-date: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (0.1.5)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ykjgo4UNXmD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cca7ce93-4761-4c4c-cefe-4751d3bd4ddb"
      },
      "source": [
        "%load_ext tensorboard\n",
        "import tensorboard\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "import tensorflow as tf\n",
        "import random \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mydXeQlDNbnR"
      },
      "source": [
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBYltugp-MdR"
      },
      "source": [
        "###Define functions\n",
        "Define functions to allow the dataset to be manipulated at a per-user level of ganularity. </br>\n",
        "Also a function is defined to count the number of weights that are set to zero. The purpose of this function is to confirm the sparsity of the model. </br>\n",
        "This method was referenced from https://www.dlology.com/blog/how-to-compress-your-keras-model-x5-smaller-with-tensorflow-model-optimization/ \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_MJqxz5z2dh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee1a2e71-71e9-40aa-f1e3-8cd34baf238e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        " \n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
        "  return dataframe.values\n",
        " \n",
        "#move_test_to_train(move_samples, move_sub_map, har_dataset_user_test, har_submap_user_test, har_dataset_user_train, har_submap_user_train)\n",
        "#######################################################################\n",
        "# Function to move selected test samples to traning dataset\n",
        "#######################################################################\n",
        "def move_test_to_train(move_samples, move_sub_map, move_ys, move_idx, har_dataset_user_test, har_submap_user_test, har_dataset_user_train, har_submap_user_train, har_y_user_test, har_y_user_train):\n",
        "    har_dataset_user_test = np.asarray(har_dataset_user_test)\n",
        "    har_submap_user_test = np.asarray(har_submap_user_test)\n",
        "    har_dataset_user_train = np.asarray(har_dataset_user_train)\n",
        "    har_submap_user_train = np.asarray(har_submap_user_train)\n",
        "    har_y_user_test = np.asarray(har_y_user_test)\n",
        "    har_y_user_train = np.asarray(har_y_user_train)\n",
        "    move_samples = np.asarray(move_samples)\n",
        "    move_ys = np.asarray(move_ys)\n",
        "    har_dataset_user_test = np.delete(har_dataset_user_test, move_idx, axis=0)\n",
        "    har_submap_user_test = np.delete(har_submap_user_test, move_idx, axis=0)\n",
        "    har_y_user_test = np.delete(har_y_user_test, move_idx, axis=0)\n",
        "    har_dataset_user_train = np.concatenate((har_dataset_user_train, move_samples))\n",
        "    har_submap_user_train = np.concatenate((har_submap_user_train, move_sub_map))\n",
        "    har_y_user_train = np.concatenate((har_y_user_train, move_ys))\n",
        "    return  har_dataset_user_test, har_submap_user_test, har_y_user_test, har_dataset_user_train, har_submap_user_train, har_y_user_train\n",
        " \n",
        "#######################################################################\n",
        "# Function to create a user dataset\n",
        "#######################################################################\n",
        "def select_user_val(har_dataset, y, sub_map, test_users, train_user, percent_mix):\n",
        "  har_dataset_user_test=[]\n",
        "  har_submap_user_test=[]\n",
        "  har_y_user_test=[]\n",
        "  for user in test_users:\n",
        "  #  har_dataset_user_test.append(har_dataset[tuple(np.where(sub_map==user))]) \n",
        "    har_dataset_user_test.extend(har_dataset[tuple(np.where(sub_map==user))].tolist()) \n",
        "    har_submap_user_test.extend(sub_map[np.where(sub_map==user)].tolist())\n",
        "    har_y_user_test.extend(y[tuple(np.where(sub_map==user))].tolist()) \n",
        "  # Generate the default training dataset \n",
        "  har_dataset_user_train=[]\n",
        "  har_submap_user_train=[]\n",
        "  har_y_user_train=[]\n",
        "  for user in train_user:\n",
        "    har_dataset_user_train.extend(har_dataset[tuple(np.where(sub_map==user))].tolist())\n",
        "    har_submap_user_train.extend(sub_map[np.where(sub_map==user)].tolist())\n",
        "    har_y_user_train.extend(y[tuple(np.where(sub_map==user))].tolist()) \n",
        " \n",
        "  ## Now allow a percentage of val users samples to enter the training dataset\n",
        "  ## Make sure that the percentage comes from each val user\n",
        " \n",
        "  for user in test_users:\n",
        "    har_user_sub_map=np.where(np.asarray(har_submap_user_test)==user)[0]\n",
        "    har_user_sub_map_cnt=np.count_nonzero(np.asarray(har_submap_user_test)==user)\n",
        "    num_take_sub_map = int(har_user_sub_map_cnt*percent_mix)\n",
        "    if(num_take_sub_map > 0) :\n",
        "      move_idx=random.sample(list(har_user_sub_map), num_take_sub_map)\n",
        "      move_samples=[har_dataset_user_test[i] for i in move_idx]  \n",
        "      move_sub_map=[har_submap_user_test[i] for i in move_idx]   \n",
        "      move_ys=[har_y_user_test[i] for i in move_idx]   \n",
        "      har_dataset_user_test, har_submap_user_test, har_y_user_test, har_dataset_user_train, har_submap_user_train, har_y_user_train \\\n",
        "        = move_test_to_train(move_samples, move_sub_map, move_ys, move_idx, har_dataset_user_test, har_submap_user_test, har_dataset_user_train, har_submap_user_train, har_y_user_test, har_y_user_train)\n",
        "  return  np.asarray(har_dataset_user_test), np.asarray(har_submap_user_test), np.asarray(har_y_user_test), np.asarray(har_dataset_user_train), np.asarray(har_submap_user_train), np.asarray(har_y_user_train)\n",
        " \n",
        " \n",
        "\n",
        "#https://www.dlology.com/blog/how-to-compress-your-keras-model-x5-smaller-with-tensorflow-model-optimization/ \n",
        "\n",
        "def check_zero_weights(model):\n",
        "  #print(model.get_weights())\n",
        "  for i, w in enumerate(model.get_weights()):\n",
        "    print(\n",
        "        \"{} -- Total:{}, Zeros: {:.2f}%\".format(\n",
        "            model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100\n",
        "        )        \n",
        "    )\n",
        "    zero_idx=np.where(w == 0)\n",
        "    print(\"i iddex is zero_idx is\", i, zero_idx)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1p_y3gPWeW2"
      },
      "source": [
        "\n",
        "### Define the CNN Model\n",
        "In this cell the CNN is defined. </br>\n",
        "It's initial weights are saved so that all experiments start from the same point to ensure fairness in the comparisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLg0SGdYp2Q6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "046cd218-6575-49da-d789-2a12a7d97276"
      },
      "source": [
        "##############################################\n",
        "#### Define the CNN ##########################        \n",
        "##############################################\n",
        "# set variables\n",
        "mix_users=True\n",
        "seg_len = 128\n",
        "num_channels = 9\n",
        "num_labels = 6\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "num_epoches = 0\n",
        "#num_batches = train_x.shape[0] // batch_size\n",
        "time_samples = 128\n",
        "feature_sensors = 9\n",
        "num_classes = 6\n",
        "\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "l = tf.keras.layers\n",
        "\n",
        "opt = 'sgd'\n",
        "l = tf.keras.layers\n",
        "model_har = tf.keras.Sequential([\n",
        "    l.Conv1D(filters=32,kernel_size=10,strides=1,activation='relu', input_shape=(time_samples, feature_sensors)),\n",
        "    l.MaxPooling1D(pool_size=4,strides=2, padding='same'),\n",
        "    l.Conv1D(filters=64,kernel_size=2,strides=1,activation='relu'),\n",
        "    l.MaxPooling1D(pool_size=4,strides=2, padding='same'),\n",
        "    l.Conv1D(filters=128,kernel_size=2,strides=2,activation='relu'),\n",
        "    l.Flatten(),\n",
        "    l.Dense(150),\n",
        "    l.Activation('tanh'),\n",
        "    l.Dropout(0.5),\n",
        "    l.Dense(50),\n",
        "    l.Activation('tanh'),\n",
        "    l.Dropout(0.5),\n",
        "    l.Dense(25),\n",
        "    l.Activation('tanh'),\n",
        "    l.Dropout(0.5),\n",
        "    l.Dense(num_labels),\n",
        "    l.Activation('softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model_har.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## This NB needs to be run multiple times for one data collection due to \n",
        "## large computation effort.  Only write out the init weights once per\n",
        "## data collection run to keep comparisions equal\n",
        "gen_init_weights = False\n",
        "if(gen_init_weights):\n",
        "  model_har.save_weights('/content/drive/My Drive/model_har_pruning_init.h5')\n",
        "\n",
        "\n",
        "\n",
        "print(model_har.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_42 (Conv1D)           (None, 119, 32)           2912      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling (None, 60, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_43 (Conv1D)           (None, 59, 64)            4160      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_29 (MaxPooling (None, 30, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_44 (Conv1D)           (None, 15, 128)           16512     \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 150)               288150    \n",
            "_________________________________________________________________\n",
            "activation_56 (Activation)   (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 50)                7550      \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 6)                 156       \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 320,715\n",
            "Trainable params: 320,715\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg7eEb5Hb_N6"
      },
      "source": [
        "## Define The Pruning Flow\n",
        "This method is the backbone of the pruning experiments. </br>\n",
        "It creates edge and central datasets. </br>\n",
        "Pruning at the central node can be enabled/disabled through switch prune_at_center </br>\n",
        "Pruning at the edge nodes can be enabled/disabled through switch prune_at_edge </br>\n",
        "Training at the edge nodes can be enabled/disabled through switch train_at_edge </br>\n",
        "Training at the central nodes is always enabled </br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7c-fsQpTzOr"
      },
      "source": [
        "def run_prune(prune_at_edge, prune_at_center, train_at_edge, har_dataset, har_dataset_y, sub_map, edge_central_ratio, num_epoches = 25, eval_before_prune=False):\n",
        "\n",
        "  total_num_users=30\n",
        "  all_users = range(1, total_num_users)\n",
        "  edge_users = random.sample(all_users, int(edge_central_ratio*total_num_users))\n",
        "  #model_har.load_weights('/content/drive/My Drive/model_har_init.h5')\n",
        "  central_users=np.setdiff1d(all_users, edge_users)\n",
        "  print(\"Edge users are:\",edge_users)\n",
        "  print(\"Central users are:\",central_users)\n",
        "\n",
        "  percent_mix=0\n",
        "  edge_x, edge_submap, edge_y, central_x, central_submap, central_y = \\\n",
        "        select_user_val(har_dataset, har_dataset_y, sub_map, edge_users, central_users, percent_mix)\n",
        "\n",
        "  central_train_x, central_test_x, central_train_y, central_test_y = train_test_split(central_x, central_y, test_size = 0.2, random_state = 0,shuffle =True)\n",
        "  edge_train_x, edge_test_x, edge_train_y, edge_test_y = train_test_split(edge_x, edge_y, test_size = 0.2, random_state = 0,shuffle =True)\n",
        "\n",
        "  logdir = tempfile.mkdtemp()\n",
        "  print('Writing training logs to ' + logdir)\n",
        "  callbacks = [tf.keras.callbacks.TensorBoard(log_dir=logdir, profile_batch=0)]\n",
        "\n",
        "  \n",
        "  model_har.load_weights('/content/drive/My Drive/model_har_pruning_init.h5')\n",
        "  if(eval_before_prune== True):\n",
        "    model_har.fit(central_train_x, central_train_y,\n",
        "           batch_size=batch_size,\n",
        "           epochs=num_epoches,\n",
        "           verbose=0,\n",
        "           callbacks=callbacks,\n",
        "           validation_data=(central_test_x, central_test_y))\n",
        "    score = model_har.evaluate(central_test_x, central_test_y, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "    check_zero_weights(model_har)\n",
        "\n",
        "  num_train_samples = central_train_x.shape[0]\n",
        "  end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * num_epoches\n",
        "  print('End step: ' + str(end_step))\n",
        "\n",
        "  ## jmoran hand set the pruning paras\n",
        "\n",
        "  if(prune_at_center==True):\n",
        "   pruning_params = {\n",
        "        'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                   final_sparsity=0.75,\n",
        "                                                   begin_step=100,\n",
        "                                                   end_step=end_step,\n",
        "                                                   frequency=100)\n",
        "    }\n",
        "  else:\n",
        "    pruning_params = {\n",
        "        'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.0,\n",
        "                                                   final_sparsity=0.0,\n",
        "                                                   begin_step=100,\n",
        "                                                   end_step=end_step,\n",
        "                                                   frequency=100)\n",
        "   }\n",
        "\n",
        "\n",
        "  central_model_har = tf.keras.Sequential([\n",
        "    sparsity.prune_low_magnitude(l.Conv1D(filters=32,kernel_size=10,strides=1,activation='relu', input_shape=(time_samples, feature_sensors)), **pruning_params),\n",
        "    l.MaxPooling1D(pool_size=4,strides=2, padding='same'),\n",
        "    sparsity.prune_low_magnitude(l.Conv1D(filters=64,kernel_size=2,strides=1,activation='relu'),**pruning_params),\n",
        "    l.MaxPooling1D(pool_size=4,strides=2, padding='same'),\n",
        "    sparsity.prune_low_magnitude(l.Conv1D(filters=128,kernel_size=2,strides=2,activation='relu'),**pruning_params),\n",
        "    l.Flatten(),\n",
        "    sparsity.prune_low_magnitude(l.Dense(150),**pruning_params),\n",
        "    l.Activation('tanh'),\n",
        "    l.Dropout(0.5),\n",
        "    sparsity.prune_low_magnitude(l.Dense(50),**pruning_params),\n",
        "    l.Activation('tanh'),\n",
        "    l.Dropout(0.5),\n",
        "    sparsity.prune_low_magnitude(l.Dense(25),**pruning_params),\n",
        "    l.Activation('tanh'),\n",
        "    l.Dropout(0.5),\n",
        "    sparsity.prune_low_magnitude(l.Dense(num_labels),**pruning_params),\n",
        "    l.Activation('softmax')\n",
        "  ])\n",
        "\n",
        "  #pruned_model_har.summary()\n",
        "  central_model_har.compile(\n",
        "     loss=tf.keras.losses.categorical_crossentropy,\n",
        "     optimizer='adam',\n",
        "     metrics=['accuracy'])\n",
        "\n",
        "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
        "# step. Also add a callback to add pruning summaries to tensorboard\n",
        "  callbacks = [\n",
        "     sparsity.UpdatePruningStep(),\n",
        "     sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
        "  ]\n",
        "\n",
        "  central_model_har.fit(central_train_x, central_train_y,\n",
        "           batch_size=batch_size,\n",
        "           epochs=num_epoches,\n",
        "           verbose=0,\n",
        "           callbacks=callbacks,\n",
        "           validation_data=(central_test_x, central_test_y))\n",
        "\n",
        "  score = central_model_har.evaluate(central_test_x, central_test_y, verbose=0)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  check_zero_weights(central_model_har)\n",
        "  central_model_har.save_weights('/content/drive/My Drive/pruned_model_har_central.h5')\n",
        "\n",
        "  if(prune_at_edge==True):\n",
        "   pruning_params_edge = {\n",
        "         'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                    final_sparsity=0.75,\n",
        "                                                     begin_step=100,\n",
        "                                                    end_step=end_step,\n",
        "                                                     frequency=100)\n",
        "   }\n",
        "  else:\n",
        "   pruning_params_edge = {\n",
        "         'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.0,\n",
        "                                                    final_sparsity=0.0,\n",
        "                                                    begin_step=100,\n",
        "                                                    end_step=end_step,\n",
        "                                                    frequency=100)\n",
        "   }\n",
        "\n",
        "  edge_pruned_model_har = tf.keras.Sequential([\n",
        "     sparsity.prune_low_magnitude(l.Conv1D(filters=32,kernel_size=10,strides=1,activation='relu', input_shape=(time_samples, feature_sensors)), **pruning_params_edge),\n",
        "     l.MaxPooling1D(pool_size=4,strides=2, padding='same'),\n",
        "     sparsity.prune_low_magnitude(l.Conv1D(filters=64,kernel_size=2,strides=1,activation='relu'),**pruning_params_edge),\n",
        "     l.MaxPooling1D(pool_size=4,strides=2, padding='same'),\n",
        "     sparsity.prune_low_magnitude(l.Conv1D(filters=128,kernel_size=2,strides=2,activation='relu'),**pruning_params_edge),\n",
        "     l.Flatten(),\n",
        "      sparsity.prune_low_magnitude(l.Dense(150),**pruning_params_edge),\n",
        "     l.Activation('tanh'),\n",
        "     l.Dropout(0.5),\n",
        "     sparsity.prune_low_magnitude(l.Dense(50),**pruning_params_edge),\n",
        "     l.Activation('tanh'),\n",
        "     l.Dropout(0.5),\n",
        "     sparsity.prune_low_magnitude(l.Dense(25),**pruning_params_edge),\n",
        "     l.Activation('tanh'),\n",
        "     l.Dropout(0.5),\n",
        "     sparsity.prune_low_magnitude(l.Dense(num_labels),**pruning_params_edge),\n",
        "      l.Activation('softmax')\n",
        "  ])\n",
        "\n",
        "  edge_pruned_model_har.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "  if(prune_at_edge==True):\n",
        "   edge_pruned_model_har=edge_pruned_model_har\n",
        "   edge_pruned_model_har.load_weights('/content/drive/My Drive/pruned_model_har_central.h5')\n",
        "  else:\n",
        "   edge_pruned_model_har=central_model_har\n",
        "\n",
        "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
        "# step. Also add a callback to add pruning summaries to tensorboard\n",
        "  callbacks = [\n",
        "     sparsity.UpdatePruningStep(),\n",
        "     sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
        "  ]\n",
        "\n",
        "  if(train_at_edge==True):\n",
        "   edge_pruned_model_har.fit(edge_train_x, edge_train_y,\n",
        "           batch_size=batch_size,\n",
        "           epochs=num_epoches,\n",
        "           verbose=0,\n",
        "           callbacks=callbacks,\n",
        "           validation_data=(edge_test_x, edge_test_y))\n",
        "\n",
        "  score = edge_pruned_model_har.evaluate(edge_test_x, edge_test_y, verbose=0)\n",
        "  print('Edge Test loss:', score[0])\n",
        "  print('Edge Test accuracy:', score[1])\n",
        "  edge_acc =  score[1]\n",
        "\n",
        "  score = central_model_har.evaluate(central_test_x, central_test_y, verbose=0)\n",
        "  print('Central Test loss:', score[0])\n",
        "  print('Central accuracy:', score[1])\n",
        "  central_acc =  score[1]\n",
        "  print(edge_pruned_model_har.summary())\n",
        "  check_zero_weights(edge_pruned_model_har)\n",
        "\n",
        "  return  central_acc, edge_acc \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YvTSXw3gLqW"
      },
      "source": [
        "### Prepare The Dataset and set the Run_prune parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgzYvhRAc6Y4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "3c2118f9-0152-4e0e-c5ff-9fe869f986e4"
      },
      "source": [
        "\n",
        "## This files contains the training users mapping\n",
        "sub_map_train = load_file('/content/drive/My Drive/Colab Notebooks/UCI_dataset/UCI HAR Dataset/train/subject_train.txt')\n",
        "train_subjects = np.unique(sub_map_train)\n",
        "print(train_subjects)\n",
        " \n",
        "sub_map_test = load_file('/content/drive/My Drive/Colab Notebooks/UCI_dataset/UCI HAR Dataset/test/subject_test.txt')\n",
        "test_subjects = np.unique(sub_map_test)\n",
        "print(test_subjects)\n",
        " \n",
        " \n",
        "har_features = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]\n",
        " \n",
        "num_of_timesamples = 128\n",
        "num_of_feature = len(har_features)\n",
        "num_of_samples = sub_map_train.shape[0] + sub_map_test.shape[0]\n",
        "print(\"num_of_samples is\",num_of_samples)\n",
        "\n",
        "sub_map = np.concatenate((sub_map_test, sub_map_train), axis =0)\n",
        "sub_map = sub_map.reshape(-1) \n",
        "print(sub_map)\n",
        "unique, counts = np.unique(sub_map, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        " \n",
        "har_feature_cnt=0\n",
        "har_dataset =  np.empty([num_of_samples, num_of_timesamples, num_of_feature])\n",
        "for har_feature in har_features:\n",
        "   har_feature_test  = load_file(f'/content/drive/My Drive/Colab Notebooks/UCI_dataset/UCI HAR Dataset/test/Inertial Signals/{har_feature}_test.txt')\n",
        "   har_feature_train = load_file(f'/content/drive/My Drive/Colab Notebooks/UCI_dataset/UCI HAR Dataset/train/Inertial Signals/{har_feature}_train.txt')\n",
        "   har_feature = np.concatenate((har_feature_test, har_feature_train), axis=0)\n",
        "   har_dataset[:, :, har_feature_cnt] = har_feature \n",
        "   har_feature_cnt += 1\n",
        " \n",
        "har_dataset_with_subject = np.expand_dims(har_dataset, axis=1)\n",
        "print(\"har_dataset_with_subject.shape is\",har_dataset_with_subject.shape)\n",
        " \n",
        "train_y =  load_file('/content/drive/My Drive/Colab Notebooks/UCI_dataset/UCI HAR Dataset/train/y_train.txt')\n",
        "test_y =  load_file('/content/drive/My Drive/Colab Notebooks/UCI_dataset/UCI HAR Dataset/test/y_test.txt')\n",
        "train_y = np.asarray(pd.get_dummies(train_y.reshape(-1, )))\n",
        "test_y = np.asarray(pd.get_dummies(test_y.reshape(-1, )))\n",
        "har_dataset_y = np.concatenate((test_y,train_y),axis=0)\n",
        "\n",
        "num_runs_per_edge_ratio=20\n",
        "edge_central_ratio_lst = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1  3  5  6  7  8 11 14 15 16 17 19 21 22 23 25 26 27 28 29 30]\n",
            "[ 2  4  9 10 12 13 18 20 24]\n",
            "num_of_samples is 10299\n",
            "[ 2  2  2 ... 30 30 30]\n",
            "{1: 347, 2: 302, 3: 341, 4: 317, 5: 302, 6: 325, 7: 308, 8: 281, 9: 288, 10: 294, 11: 316, 12: 320, 13: 327, 14: 323, 15: 328, 16: 366, 17: 368, 18: 364, 19: 360, 20: 354, 21: 408, 22: 321, 23: 372, 24: 381, 25: 409, 26: 392, 27: 376, 28: 382, 29: 344, 30: 383}\n",
            "har_dataset_with_subject.shape is (10299, 1, 128, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh8DNMHKg5wH"
      },
      "source": [
        "### Run Pruning experiment with: </br>\n",
        "prune_at_edge=False</br>\n",
        "prune_at_center=False</br>\n",
        "train_at_edge=False</br> \n",
        "Results will be printed to file \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4JAWtcDRKtY"
      },
      "source": [
        "prune_at_edge=False\n",
        "prune_at_center=False\n",
        "train_at_edge=False\n",
        "\n",
        "\n",
        "central_acc_lst=[]\n",
        "edge_acc_lst=[]\n",
        "\n",
        "for edge_central_ratio in edge_central_ratio_lst:\n",
        "  for run in range(num_runs_per_edge_ratio):\n",
        "    central_acc, edge_acc = run_prune(prune_at_edge=prune_at_edge, prune_at_center=prune_at_center, train_at_edge=train_at_edge, har_dataset=har_dataset, har_dataset_y=har_dataset_y, sub_map=sub_map, edge_central_ratio=edge_central_ratio)\n",
        "    central_acc_lst.append(central_acc)\n",
        "    edge_acc_lst.append(edge_acc)\n",
        "\n",
        "with open('/content/drive/My Drive/pef_pcf_tef_bl_20.txt', 'w') as f:\n",
        "        f.writelines(\"%s\\n\" % central_acc_lst)\n",
        "        f.writelines(\"%s\\n\" % edge_acc_lst)   \n",
        "print(\"central_acc_lst is\", central_acc_lst)\n",
        "print(\"edge_acc_lst is\",edge_acc_lst)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk8KiMYjhemh"
      },
      "source": [
        "### Run Pruning experiment with: </br>\n",
        "prune_at_edge=False</br>\n",
        "prune_at_center=True</br>\n",
        "train_at_edge=False</br> \n",
        "Results will be printed to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuefrW6VRnyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06f35633-e8ee-4fb9-c56b-583870509b9d"
      },
      "source": [
        "\n",
        "prune_at_edge=False\n",
        "prune_at_center=True\n",
        "train_at_edge=False\n",
        "\n",
        "central_acc_lst1=[]\n",
        "edge_acc_lst1=[]\n",
        "\n",
        "\n",
        "for edge_central_ratio in edge_central_ratio_lst:\n",
        "  for run in range(num_runs_per_edge_ratio):\n",
        "    central_acc, edge_acc = run_prune(prune_at_edge=prune_at_edge, prune_at_center=prune_at_center, train_at_edge=train_at_edge, har_dataset=har_dataset, har_dataset_y=har_dataset_y, sub_map=sub_map, edge_central_ratio=edge_central_ratio)\n",
        "    central_acc_lst1.append(central_acc)\n",
        "    edge_acc_lst1.append(edge_acc)\n",
        "\n",
        "with open('/content/drive/My Drive/pef_pct_tef_bl_20.txt', 'w') as f:\n",
        "        f.writelines(\"%s\\n\" % central_acc_lst1)\n",
        "        f.writelines(\"%s\\n\" % edge_acc_lst1)   \n",
        "\n",
        "print(\"central_acc_lst is\", central_acc_lst1)\n",
        "print(\"edge_acc_lst is\",edge_acc_lst1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Edge users are: [1, 16, 14, 6, 3, 19, 5, 24, 9, 15, 17, 29]\n",
            "Central users are: [ 2  4  7  8 10 11 12 13 18 20 21 22 23 25 26 27 28]\n",
            "Writing training logs to /tmp/tmpa3ibxt36\n",
            "End step: 1175\n",
            "Test loss: 0.09733313001641307\n",
            "Test accuracy: 0.97262615\n",
            "prune_low_magnitude_conv1d_45/kernel:0 -- Total:2880, Zeros: 75.00%\n",
            "i iddex is zero_idx is 0 (array([0, 0, 0, ..., 9, 9, 9]), array([0, 0, 0, ..., 8, 8, 8]), array([ 0,  1,  2, ..., 27, 29, 30]))\n",
            "prune_low_magnitude_conv1d_45/bias:0 -- Total:32, Zeros: 0.00%\n",
            "i iddex is zero_idx is 1 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_45/mask:0 -- Total:2880, Zeros: 75.00%\n",
            "i iddex is zero_idx is 2 (array([0, 0, 0, ..., 9, 9, 9]), array([0, 0, 0, ..., 8, 8, 8]), array([ 0,  1,  2, ..., 27, 29, 30]))\n",
            "prune_low_magnitude_conv1d_45/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 3 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_45/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 4 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_46/kernel:0 -- Total:4096, Zeros: 75.00%\n",
            "i iddex is zero_idx is 5 (array([0, 0, 0, ..., 1, 1, 1]), array([ 0,  0,  0, ..., 31, 31, 31]), array([ 1,  2,  4, ..., 60, 61, 62]))\n",
            "prune_low_magnitude_conv1d_46/bias:0 -- Total:64, Zeros: 0.00%\n",
            "i iddex is zero_idx is 6 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_46/mask:0 -- Total:4096, Zeros: 75.00%\n",
            "i iddex is zero_idx is 7 (array([0, 0, 0, ..., 1, 1, 1]), array([ 0,  0,  0, ..., 31, 31, 31]), array([ 1,  2,  4, ..., 60, 61, 62]))\n",
            "prune_low_magnitude_conv1d_46/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 8 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_46/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 9 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_47/kernel:0 -- Total:16384, Zeros: 74.99%\n",
            "i iddex is zero_idx is 10 (array([0, 0, 0, ..., 1, 1, 1]), array([ 0,  0,  0, ..., 63, 63, 63]), array([  1,   3,   4, ..., 125, 126, 127]))\n",
            "prune_low_magnitude_conv1d_47/bias:0 -- Total:128, Zeros: 0.00%\n",
            "i iddex is zero_idx is 11 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_47/mask:0 -- Total:16384, Zeros: 74.99%\n",
            "i iddex is zero_idx is 12 (array([0, 0, 0, ..., 1, 1, 1]), array([ 0,  0,  0, ..., 63, 63, 63]), array([  1,   3,   4, ..., 125, 126, 127]))\n",
            "prune_low_magnitude_conv1d_47/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 13 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_47/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 14 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_60/kernel:0 -- Total:288000, Zeros: 74.99%\n",
            "i iddex is zero_idx is 15 (array([   0,    0,    0, ..., 1919, 1919, 1919]), array([  0,   1,   8, ..., 146, 147, 149]))\n",
            "prune_low_magnitude_dense_60/bias:0 -- Total:150, Zeros: 0.00%\n",
            "i iddex is zero_idx is 16 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_60/mask:0 -- Total:288000, Zeros: 74.99%\n",
            "i iddex is zero_idx is 17 (array([   0,    0,    0, ..., 1919, 1919, 1919]), array([  0,   1,   8, ..., 146, 147, 149]))\n",
            "prune_low_magnitude_dense_60/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 18 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_60/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 19 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_61/kernel:0 -- Total:7500, Zeros: 74.99%\n",
            "i iddex is zero_idx is 20 (array([  0,   0,   0, ..., 149, 149, 149]), array([ 0,  1,  3, ..., 45, 47, 49]))\n",
            "prune_low_magnitude_dense_61/bias:0 -- Total:50, Zeros: 0.00%\n",
            "i iddex is zero_idx is 21 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_61/mask:0 -- Total:7500, Zeros: 74.99%\n",
            "i iddex is zero_idx is 22 (array([  0,   0,   0, ..., 149, 149, 149]), array([ 0,  1,  3, ..., 45, 47, 49]))\n",
            "prune_low_magnitude_dense_61/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 23 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_61/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 24 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_62/kernel:0 -- Total:1250, Zeros: 74.96%\n",
            "i iddex is zero_idx is 25 (array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "        1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "        2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
            "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
            "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,\n",
            "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,\n",
            "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,\n",
            "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,\n",
            "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,\n",
            "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
            "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "       12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "       14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
            "       15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "       16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
            "       17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "       18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19,\n",
            "       19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
            "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21,\n",
            "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22,\n",
            "       22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,\n",
            "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24,\n",
            "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25,\n",
            "       25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
            "       26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
            "       26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
            "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
            "       28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29,\n",
            "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30,\n",
            "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31,\n",
            "       31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32,\n",
            "       32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33,\n",
            "       33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "       33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
            "       34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "       35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
            "       36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37,\n",
            "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38,\n",
            "       38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39,\n",
            "       39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40,\n",
            "       40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41,\n",
            "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42,\n",
            "       42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
            "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
            "       43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
            "       44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45,\n",
            "       45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46,\n",
            "       46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47,\n",
            "       47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48,\n",
            "       48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
            "       49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
            "       49, 49]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 14, 15, 16, 17, 18,\n",
            "       19, 20, 23,  0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 14, 16, 18,\n",
            "       20, 21, 22, 23, 24,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12, 13,\n",
            "       14, 15, 17, 18, 21, 23, 24,  0,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
            "       11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23,  0,  1,  2,  3,  7,  8,\n",
            "        9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 24,  0,  1,  2,  4,  9,\n",
            "       10, 12, 14, 15, 19, 20, 21, 22, 23, 24,  0,  1,  3,  4,  5,  7,  8,\n",
            "        9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24,  1,  5,  6,  7,\n",
            "        8,  9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23,  1,  2,  3,\n",
            "        4,  6,  7,  8, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24,  0,  1,  2,\n",
            "        4,  5,  7,  8,  9, 10, 11, 14, 17, 18, 19, 20, 21, 24,  0,  1,  2,\n",
            "        3,  5,  6,  8, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24,\n",
            "        0,  2,  4,  5,  8,  9, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23,\n",
            "        1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 14, 15, 16, 19, 20, 21, 23,\n",
            "       24,  2,  3,  5,  6,  7,  8, 11, 13, 14, 16, 17, 18, 19, 21, 22, 24,\n",
            "        0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12, 13, 14, 16, 18, 19, 20,\n",
            "       22, 23, 24,  0,  1,  2,  3,  4,  5,  8, 10, 11, 12, 13, 15, 16, 17,\n",
            "       18, 20, 21, 23,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 14, 15,\n",
            "       18, 19, 20, 22, 23, 24,  0,  1,  2,  3,  4,  9, 10, 11, 14, 15, 16,\n",
            "       17, 18, 19, 22, 23,  0,  1,  3,  4,  5,  6,  8,  9, 10, 11, 13, 14,\n",
            "       15, 16, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  5,  6,  7,  8,\n",
            "       10, 12, 13, 14, 15, 17, 18, 21, 22,  2,  4,  5,  6,  7,  8,  9, 10,\n",
            "       11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23,  0,  1,  3,  4,  5,  6,\n",
            "        7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 23, 24,  0,  2,  3,  6,\n",
            "        8,  9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 23, 24,  0,  1,  2,  5,\n",
            "        6,  7,  8,  9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 24,  0,  1,\n",
            "        3,  4,  5,  6, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 24,  0,  1,\n",
            "        2,  3,  4,  5,  7,  8,  9, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24,\n",
            "        0,  1,  2,  3,  4,  5,  6,  8, 10, 11, 12, 13, 14, 15, 17, 18, 19,\n",
            "       20, 21, 22, 24,  0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 12, 13, 14,\n",
            "       15, 16, 17, 18, 19, 20, 21, 22,  0,  1,  2,  4,  5,  6,  7,  8, 10,\n",
            "       11, 12, 13, 14, 15, 16, 18, 19, 22, 24,  0,  2,  3,  4,  6,  8, 10,\n",
            "       13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  4,  5,\n",
            "        6,  7,  8,  9, 10, 13, 15, 16, 17, 19, 21, 22, 23, 24,  2,  3,  4,\n",
            "        6,  7,  8,  9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24,  0,  1,\n",
            "        2,  3,  5,  8,  9, 11, 12, 14, 17, 18, 19, 22, 23, 24,  0,  1,  2,\n",
            "        3,  4,  5,  6,  7,  8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22,\n",
            "       24,  0,  1,  2,  3,  5,  6,  7,  8,  9, 11, 12, 13, 15, 16, 17, 19,\n",
            "       20, 21, 22, 23, 24,  0,  2,  3,  5,  6,  7,  9, 10, 11, 12, 16, 17,\n",
            "       18, 19, 20, 21, 22, 24,  0,  1,  2,  4,  5,  7,  8,  9, 10, 12, 14,\n",
            "       15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,  8,\n",
            "        9, 10, 12, 13, 14, 15, 17, 19, 21, 23, 24,  0,  1,  4,  5,  6,  7,\n",
            "        9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,\n",
            "        2,  4,  5,  7,  8,  9, 10, 11, 14, 15, 17, 18, 20, 21, 22,  3,  5,\n",
            "        6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24,  1,\n",
            "        2,  4,  5,  6,  7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 24,  0,  1,\n",
            "        2,  3,  4,  5,  8,  9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24,\n",
            "        0,  1,  2,  4,  8,  9, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23,\n",
            "       24,  0,  1,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "       18, 19, 20, 21, 23, 24,  0,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13,\n",
            "       14, 15, 17, 18, 19, 20, 21, 22, 23,  0,  1,  2,  4,  5,  6,  7,  8,\n",
            "        9, 10, 11, 12, 13, 15, 19, 20, 21, 22,  0,  2,  3,  5,  6,  7,  8,\n",
            "        9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23,  0,  3,  4,\n",
            "        5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24,\n",
            "        0,  1,  2,  3,  4,  6,  7,  8,  9, 11, 16, 17, 18, 19, 20, 21, 22,\n",
            "       23, 24]))\n",
            "prune_low_magnitude_dense_62/bias:0 -- Total:25, Zeros: 0.00%\n",
            "i iddex is zero_idx is 26 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_62/mask:0 -- Total:1250, Zeros: 74.96%\n",
            "i iddex is zero_idx is 27 (array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "        1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "        2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
            "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
            "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,\n",
            "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,\n",
            "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,\n",
            "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,\n",
            "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,\n",
            "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
            "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "       12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "       14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
            "       15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "       16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
            "       17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "       18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19,\n",
            "       19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
            "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21,\n",
            "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22,\n",
            "       22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,\n",
            "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24,\n",
            "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25,\n",
            "       25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
            "       26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
            "       26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
            "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
            "       28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29,\n",
            "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30,\n",
            "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31,\n",
            "       31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32,\n",
            "       32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33,\n",
            "       33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "       33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
            "       34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "       35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
            "       36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37,\n",
            "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38,\n",
            "       38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39,\n",
            "       39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40,\n",
            "       40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41,\n",
            "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42,\n",
            "       42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
            "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
            "       43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
            "       44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45,\n",
            "       45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46,\n",
            "       46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47,\n",
            "       47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48,\n",
            "       48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
            "       49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
            "       49, 49]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 14, 15, 16, 17, 18,\n",
            "       19, 20, 23,  0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 14, 16, 18,\n",
            "       20, 21, 22, 23, 24,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12, 13,\n",
            "       14, 15, 17, 18, 21, 23, 24,  0,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
            "       11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23,  0,  1,  2,  3,  7,  8,\n",
            "        9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 24,  0,  1,  2,  4,  9,\n",
            "       10, 12, 14, 15, 19, 20, 21, 22, 23, 24,  0,  1,  3,  4,  5,  7,  8,\n",
            "        9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24,  1,  5,  6,  7,\n",
            "        8,  9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23,  1,  2,  3,\n",
            "        4,  6,  7,  8, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24,  0,  1,  2,\n",
            "        4,  5,  7,  8,  9, 10, 11, 14, 17, 18, 19, 20, 21, 24,  0,  1,  2,\n",
            "        3,  5,  6,  8, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24,\n",
            "        0,  2,  4,  5,  8,  9, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23,\n",
            "        1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 14, 15, 16, 19, 20, 21, 23,\n",
            "       24,  2,  3,  5,  6,  7,  8, 11, 13, 14, 16, 17, 18, 19, 21, 22, 24,\n",
            "        0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12, 13, 14, 16, 18, 19, 20,\n",
            "       22, 23, 24,  0,  1,  2,  3,  4,  5,  8, 10, 11, 12, 13, 15, 16, 17,\n",
            "       18, 20, 21, 23,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 14, 15,\n",
            "       18, 19, 20, 22, 23, 24,  0,  1,  2,  3,  4,  9, 10, 11, 14, 15, 16,\n",
            "       17, 18, 19, 22, 23,  0,  1,  3,  4,  5,  6,  8,  9, 10, 11, 13, 14,\n",
            "       15, 16, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  5,  6,  7,  8,\n",
            "       10, 12, 13, 14, 15, 17, 18, 21, 22,  2,  4,  5,  6,  7,  8,  9, 10,\n",
            "       11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23,  0,  1,  3,  4,  5,  6,\n",
            "        7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 23, 24,  0,  2,  3,  6,\n",
            "        8,  9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 23, 24,  0,  1,  2,  5,\n",
            "        6,  7,  8,  9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 24,  0,  1,\n",
            "        3,  4,  5,  6, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 24,  0,  1,\n",
            "        2,  3,  4,  5,  7,  8,  9, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24,\n",
            "        0,  1,  2,  3,  4,  5,  6,  8, 10, 11, 12, 13, 14, 15, 17, 18, 19,\n",
            "       20, 21, 22, 24,  0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 12, 13, 14,\n",
            "       15, 16, 17, 18, 19, 20, 21, 22,  0,  1,  2,  4,  5,  6,  7,  8, 10,\n",
            "       11, 12, 13, 14, 15, 16, 18, 19, 22, 24,  0,  2,  3,  4,  6,  8, 10,\n",
            "       13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  4,  5,\n",
            "        6,  7,  8,  9, 10, 13, 15, 16, 17, 19, 21, 22, 23, 24,  2,  3,  4,\n",
            "        6,  7,  8,  9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24,  0,  1,\n",
            "        2,  3,  5,  8,  9, 11, 12, 14, 17, 18, 19, 22, 23, 24,  0,  1,  2,\n",
            "        3,  4,  5,  6,  7,  8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22,\n",
            "       24,  0,  1,  2,  3,  5,  6,  7,  8,  9, 11, 12, 13, 15, 16, 17, 19,\n",
            "       20, 21, 22, 23, 24,  0,  2,  3,  5,  6,  7,  9, 10, 11, 12, 16, 17,\n",
            "       18, 19, 20, 21, 22, 24,  0,  1,  2,  4,  5,  7,  8,  9, 10, 12, 14,\n",
            "       15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,  8,\n",
            "        9, 10, 12, 13, 14, 15, 17, 19, 21, 23, 24,  0,  1,  4,  5,  6,  7,\n",
            "        9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,\n",
            "        2,  4,  5,  7,  8,  9, 10, 11, 14, 15, 17, 18, 20, 21, 22,  3,  5,\n",
            "        6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24,  1,\n",
            "        2,  4,  5,  6,  7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 24,  0,  1,\n",
            "        2,  3,  4,  5,  8,  9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24,\n",
            "        0,  1,  2,  4,  8,  9, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23,\n",
            "       24,  0,  1,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "       18, 19, 20, 21, 23, 24,  0,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13,\n",
            "       14, 15, 17, 18, 19, 20, 21, 22, 23,  0,  1,  2,  4,  5,  6,  7,  8,\n",
            "        9, 10, 11, 12, 13, 15, 19, 20, 21, 22,  0,  2,  3,  5,  6,  7,  8,\n",
            "        9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23,  0,  3,  4,\n",
            "        5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24,\n",
            "        0,  1,  2,  3,  4,  6,  7,  8,  9, 11, 16, 17, 18, 19, 20, 21, 22,\n",
            "       23, 24]))\n",
            "prune_low_magnitude_dense_62/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 28 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_62/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 29 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_63/kernel:0 -- Total:150, Zeros: 74.67%\n",
            "i iddex is zero_idx is 30 (array([ 0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,\n",
            "        3,  4,  4,  4,  4,  5,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,\n",
            "        7,  7,  8,  8,  8,  8,  8,  9,  9,  9, 10, 10, 10, 10, 10, 10, 11,\n",
            "       11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 15,\n",
            "       15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 18, 18,\n",
            "       18, 18, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 21, 21, 22,\n",
            "       22, 22, 22, 23, 23, 23, 24, 24, 24, 24]), array([1, 3, 4, 5, 0, 1, 2, 3, 4, 0, 3, 4, 5, 0, 2, 3, 4, 5, 0, 2, 3, 5,\n",
            "       0, 1, 3, 4, 5, 0, 1, 2, 5, 1, 2, 3, 4, 5, 0, 2, 3, 4, 5, 2, 4, 5,\n",
            "       0, 1, 2, 3, 4, 5, 0, 1, 5, 0, 1, 3, 4, 5, 0, 1, 2, 4, 5, 0, 1, 3,\n",
            "       5, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 0, 3, 4, 5, 1,\n",
            "       2, 3, 4, 5, 0, 2, 3, 4, 5, 0, 1, 3, 4, 0, 1, 2, 5, 0, 1, 3, 0, 2,\n",
            "       3, 4]))\n",
            "prune_low_magnitude_dense_63/bias:0 -- Total:6, Zeros: 0.00%\n",
            "i iddex is zero_idx is 31 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_63/mask:0 -- Total:150, Zeros: 74.67%\n",
            "i iddex is zero_idx is 32 (array([ 0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,\n",
            "        3,  4,  4,  4,  4,  5,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,\n",
            "        7,  7,  8,  8,  8,  8,  8,  9,  9,  9, 10, 10, 10, 10, 10, 10, 11,\n",
            "       11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 15,\n",
            "       15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 18, 18,\n",
            "       18, 18, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 21, 21, 22,\n",
            "       22, 22, 22, 23, 23, 23, 24, 24, 24, 24]), array([1, 3, 4, 5, 0, 1, 2, 3, 4, 0, 3, 4, 5, 0, 2, 3, 4, 5, 0, 2, 3, 5,\n",
            "       0, 1, 3, 4, 5, 0, 1, 2, 5, 1, 2, 3, 4, 5, 0, 2, 3, 4, 5, 2, 4, 5,\n",
            "       0, 1, 2, 3, 4, 5, 0, 1, 5, 0, 1, 3, 4, 5, 0, 1, 2, 4, 5, 0, 1, 3,\n",
            "       5, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 0, 3, 4, 5, 1,\n",
            "       2, 3, 4, 5, 0, 2, 3, 4, 5, 0, 1, 3, 4, 0, 1, 2, 5, 0, 1, 3, 0, 2,\n",
            "       3, 4]))\n",
            "prune_low_magnitude_dense_63/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 33 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_63/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 34 (array([], dtype=int64),)\n",
            "Edge Test loss: 0.38830939461848485\n",
            "Edge Test accuracy: 0.9006135\n",
            "Central Test loss: 0.09733313001641307\n",
            "Central accuracy: 0.97262615\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_conv1d_4 (None, 119, 32)           5794      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_30 (MaxPooling (None, 60, 32)            0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_4 (None, 59, 64)            8258      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_31 (MaxPooling (None, 30, 64)            0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_4 (None, 15, 128)           32898     \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_60 (None, 150)               576152    \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_61 (None, 50)                15052     \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_62 (None, 25)                2527      \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_63 (None, 6)                 308       \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 640,989\n",
            "Trainable params: 320,715\n",
            "Non-trainable params: 320,274\n",
            "_________________________________________________________________\n",
            "None\n",
            "prune_low_magnitude_conv1d_45/kernel:0 -- Total:2880, Zeros: 75.00%\n",
            "i iddex is zero_idx is 0 (array([0, 0, 0, ..., 9, 9, 9]), array([0, 0, 0, ..., 8, 8, 8]), array([ 0,  1,  2, ..., 27, 29, 30]))\n",
            "prune_low_magnitude_conv1d_45/bias:0 -- Total:32, Zeros: 0.00%\n",
            "i iddex is zero_idx is 1 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_45/mask:0 -- Total:2880, Zeros: 75.00%\n",
            "i iddex is zero_idx is 2 (array([0, 0, 0, ..., 9, 9, 9]), array([0, 0, 0, ..., 8, 8, 8]), array([ 0,  1,  2, ..., 27, 29, 30]))\n",
            "prune_low_magnitude_conv1d_45/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 3 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_45/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 4 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_46/kernel:0 -- Total:4096, Zeros: 75.00%\n",
            "i iddex is zero_idx is 5 (array([0, 0, 0, ..., 1, 1, 1]), array([ 0,  0,  0, ..., 31, 31, 31]), array([ 1,  2,  4, ..., 60, 61, 62]))\n",
            "prune_low_magnitude_conv1d_46/bias:0 -- Total:64, Zeros: 0.00%\n",
            "i iddex is zero_idx is 6 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_46/mask:0 -- Total:4096, Zeros: 75.00%\n",
            "i iddex is zero_idx is 7 (array([0, 0, 0, ..., 1, 1, 1]), array([ 0,  0,  0, ..., 31, 31, 31]), array([ 1,  2,  4, ..., 60, 61, 62]))\n",
            "prune_low_magnitude_conv1d_46/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 8 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_46/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 9 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_47/kernel:0 -- Total:16384, Zeros: 74.99%\n",
            "i iddex is zero_idx is 10 (array([0, 0, 0, ..., 1, 1, 1]), array([ 0,  0,  0, ..., 63, 63, 63]), array([  1,   3,   4, ..., 125, 126, 127]))\n",
            "prune_low_magnitude_conv1d_47/bias:0 -- Total:128, Zeros: 0.00%\n",
            "i iddex is zero_idx is 11 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_47/mask:0 -- Total:16384, Zeros: 74.99%\n",
            "i iddex is zero_idx is 12 (array([0, 0, 0, ..., 1, 1, 1]), array([ 0,  0,  0, ..., 63, 63, 63]), array([  1,   3,   4, ..., 125, 126, 127]))\n",
            "prune_low_magnitude_conv1d_47/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 13 (array([], dtype=int64),)\n",
            "prune_low_magnitude_conv1d_47/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 14 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_60/kernel:0 -- Total:288000, Zeros: 74.99%\n",
            "i iddex is zero_idx is 15 (array([   0,    0,    0, ..., 1919, 1919, 1919]), array([  0,   1,   8, ..., 146, 147, 149]))\n",
            "prune_low_magnitude_dense_60/bias:0 -- Total:150, Zeros: 0.00%\n",
            "i iddex is zero_idx is 16 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_60/mask:0 -- Total:288000, Zeros: 74.99%\n",
            "i iddex is zero_idx is 17 (array([   0,    0,    0, ..., 1919, 1919, 1919]), array([  0,   1,   8, ..., 146, 147, 149]))\n",
            "prune_low_magnitude_dense_60/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 18 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_60/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 19 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_61/kernel:0 -- Total:7500, Zeros: 74.99%\n",
            "i iddex is zero_idx is 20 (array([  0,   0,   0, ..., 149, 149, 149]), array([ 0,  1,  3, ..., 45, 47, 49]))\n",
            "prune_low_magnitude_dense_61/bias:0 -- Total:50, Zeros: 0.00%\n",
            "i iddex is zero_idx is 21 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_61/mask:0 -- Total:7500, Zeros: 74.99%\n",
            "i iddex is zero_idx is 22 (array([  0,   0,   0, ..., 149, 149, 149]), array([ 0,  1,  3, ..., 45, 47, 49]))\n",
            "prune_low_magnitude_dense_61/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 23 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_61/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 24 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_62/kernel:0 -- Total:1250, Zeros: 74.96%\n",
            "i iddex is zero_idx is 25 (array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "        1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "        2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
            "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
            "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,\n",
            "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,\n",
            "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,\n",
            "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,\n",
            "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,\n",
            "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
            "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "       12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "       14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
            "       15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "       16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
            "       17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "       18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19,\n",
            "       19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
            "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21,\n",
            "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22,\n",
            "       22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,\n",
            "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24,\n",
            "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25,\n",
            "       25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
            "       26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
            "       26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
            "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
            "       28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29,\n",
            "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30,\n",
            "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31,\n",
            "       31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32,\n",
            "       32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33,\n",
            "       33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "       33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
            "       34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "       35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
            "       36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37,\n",
            "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38,\n",
            "       38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39,\n",
            "       39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40,\n",
            "       40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41,\n",
            "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42,\n",
            "       42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
            "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
            "       43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
            "       44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45,\n",
            "       45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46,\n",
            "       46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47,\n",
            "       47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48,\n",
            "       48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
            "       49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
            "       49, 49]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 14, 15, 16, 17, 18,\n",
            "       19, 20, 23,  0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 14, 16, 18,\n",
            "       20, 21, 22, 23, 24,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12, 13,\n",
            "       14, 15, 17, 18, 21, 23, 24,  0,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
            "       11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23,  0,  1,  2,  3,  7,  8,\n",
            "        9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 24,  0,  1,  2,  4,  9,\n",
            "       10, 12, 14, 15, 19, 20, 21, 22, 23, 24,  0,  1,  3,  4,  5,  7,  8,\n",
            "        9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24,  1,  5,  6,  7,\n",
            "        8,  9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23,  1,  2,  3,\n",
            "        4,  6,  7,  8, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24,  0,  1,  2,\n",
            "        4,  5,  7,  8,  9, 10, 11, 14, 17, 18, 19, 20, 21, 24,  0,  1,  2,\n",
            "        3,  5,  6,  8, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24,\n",
            "        0,  2,  4,  5,  8,  9, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23,\n",
            "        1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 14, 15, 16, 19, 20, 21, 23,\n",
            "       24,  2,  3,  5,  6,  7,  8, 11, 13, 14, 16, 17, 18, 19, 21, 22, 24,\n",
            "        0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12, 13, 14, 16, 18, 19, 20,\n",
            "       22, 23, 24,  0,  1,  2,  3,  4,  5,  8, 10, 11, 12, 13, 15, 16, 17,\n",
            "       18, 20, 21, 23,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 14, 15,\n",
            "       18, 19, 20, 22, 23, 24,  0,  1,  2,  3,  4,  9, 10, 11, 14, 15, 16,\n",
            "       17, 18, 19, 22, 23,  0,  1,  3,  4,  5,  6,  8,  9, 10, 11, 13, 14,\n",
            "       15, 16, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  5,  6,  7,  8,\n",
            "       10, 12, 13, 14, 15, 17, 18, 21, 22,  2,  4,  5,  6,  7,  8,  9, 10,\n",
            "       11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23,  0,  1,  3,  4,  5,  6,\n",
            "        7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 23, 24,  0,  2,  3,  6,\n",
            "        8,  9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 23, 24,  0,  1,  2,  5,\n",
            "        6,  7,  8,  9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 24,  0,  1,\n",
            "        3,  4,  5,  6, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 24,  0,  1,\n",
            "        2,  3,  4,  5,  7,  8,  9, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24,\n",
            "        0,  1,  2,  3,  4,  5,  6,  8, 10, 11, 12, 13, 14, 15, 17, 18, 19,\n",
            "       20, 21, 22, 24,  0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 12, 13, 14,\n",
            "       15, 16, 17, 18, 19, 20, 21, 22,  0,  1,  2,  4,  5,  6,  7,  8, 10,\n",
            "       11, 12, 13, 14, 15, 16, 18, 19, 22, 24,  0,  2,  3,  4,  6,  8, 10,\n",
            "       13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  4,  5,\n",
            "        6,  7,  8,  9, 10, 13, 15, 16, 17, 19, 21, 22, 23, 24,  2,  3,  4,\n",
            "        6,  7,  8,  9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24,  0,  1,\n",
            "        2,  3,  5,  8,  9, 11, 12, 14, 17, 18, 19, 22, 23, 24,  0,  1,  2,\n",
            "        3,  4,  5,  6,  7,  8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22,\n",
            "       24,  0,  1,  2,  3,  5,  6,  7,  8,  9, 11, 12, 13, 15, 16, 17, 19,\n",
            "       20, 21, 22, 23, 24,  0,  2,  3,  5,  6,  7,  9, 10, 11, 12, 16, 17,\n",
            "       18, 19, 20, 21, 22, 24,  0,  1,  2,  4,  5,  7,  8,  9, 10, 12, 14,\n",
            "       15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,  8,\n",
            "        9, 10, 12, 13, 14, 15, 17, 19, 21, 23, 24,  0,  1,  4,  5,  6,  7,\n",
            "        9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,\n",
            "        2,  4,  5,  7,  8,  9, 10, 11, 14, 15, 17, 18, 20, 21, 22,  3,  5,\n",
            "        6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24,  1,\n",
            "        2,  4,  5,  6,  7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 24,  0,  1,\n",
            "        2,  3,  4,  5,  8,  9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24,\n",
            "        0,  1,  2,  4,  8,  9, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23,\n",
            "       24,  0,  1,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "       18, 19, 20, 21, 23, 24,  0,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13,\n",
            "       14, 15, 17, 18, 19, 20, 21, 22, 23,  0,  1,  2,  4,  5,  6,  7,  8,\n",
            "        9, 10, 11, 12, 13, 15, 19, 20, 21, 22,  0,  2,  3,  5,  6,  7,  8,\n",
            "        9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23,  0,  3,  4,\n",
            "        5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24,\n",
            "        0,  1,  2,  3,  4,  6,  7,  8,  9, 11, 16, 17, 18, 19, 20, 21, 22,\n",
            "       23, 24]))\n",
            "prune_low_magnitude_dense_62/bias:0 -- Total:25, Zeros: 0.00%\n",
            "i iddex is zero_idx is 26 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_62/mask:0 -- Total:1250, Zeros: 74.96%\n",
            "i iddex is zero_idx is 27 (array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "        1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "        2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
            "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
            "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,\n",
            "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,\n",
            "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,\n",
            "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,\n",
            "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,\n",
            "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
            "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "       12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "       14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
            "       15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
            "       16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
            "       17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "       18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19,\n",
            "       19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
            "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21,\n",
            "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22,\n",
            "       22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,\n",
            "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24,\n",
            "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25,\n",
            "       25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
            "       26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
            "       26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
            "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
            "       28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29,\n",
            "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30,\n",
            "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31,\n",
            "       31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32,\n",
            "       32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33,\n",
            "       33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
            "       33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
            "       34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
            "       35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
            "       36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37,\n",
            "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38,\n",
            "       38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39,\n",
            "       39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40,\n",
            "       40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41,\n",
            "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42,\n",
            "       42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
            "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
            "       43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
            "       44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45,\n",
            "       45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46,\n",
            "       46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47,\n",
            "       47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48,\n",
            "       48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
            "       49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
            "       49, 49]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12, 14, 15, 16, 17, 18,\n",
            "       19, 20, 23,  0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 14, 16, 18,\n",
            "       20, 21, 22, 23, 24,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12, 13,\n",
            "       14, 15, 17, 18, 21, 23, 24,  0,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
            "       11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23,  0,  1,  2,  3,  7,  8,\n",
            "        9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 24,  0,  1,  2,  4,  9,\n",
            "       10, 12, 14, 15, 19, 20, 21, 22, 23, 24,  0,  1,  3,  4,  5,  7,  8,\n",
            "        9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24,  1,  5,  6,  7,\n",
            "        8,  9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23,  1,  2,  3,\n",
            "        4,  6,  7,  8, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24,  0,  1,  2,\n",
            "        4,  5,  7,  8,  9, 10, 11, 14, 17, 18, 19, 20, 21, 24,  0,  1,  2,\n",
            "        3,  5,  6,  8, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24,\n",
            "        0,  2,  4,  5,  8,  9, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23,\n",
            "        1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 14, 15, 16, 19, 20, 21, 23,\n",
            "       24,  2,  3,  5,  6,  7,  8, 11, 13, 14, 16, 17, 18, 19, 21, 22, 24,\n",
            "        0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12, 13, 14, 16, 18, 19, 20,\n",
            "       22, 23, 24,  0,  1,  2,  3,  4,  5,  8, 10, 11, 12, 13, 15, 16, 17,\n",
            "       18, 20, 21, 23,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 14, 15,\n",
            "       18, 19, 20, 22, 23, 24,  0,  1,  2,  3,  4,  9, 10, 11, 14, 15, 16,\n",
            "       17, 18, 19, 22, 23,  0,  1,  3,  4,  5,  6,  8,  9, 10, 11, 13, 14,\n",
            "       15, 16, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  5,  6,  7,  8,\n",
            "       10, 12, 13, 14, 15, 17, 18, 21, 22,  2,  4,  5,  6,  7,  8,  9, 10,\n",
            "       11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23,  0,  1,  3,  4,  5,  6,\n",
            "        7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 23, 24,  0,  2,  3,  6,\n",
            "        8,  9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 23, 24,  0,  1,  2,  5,\n",
            "        6,  7,  8,  9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 24,  0,  1,\n",
            "        3,  4,  5,  6, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 24,  0,  1,\n",
            "        2,  3,  4,  5,  7,  8,  9, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24,\n",
            "        0,  1,  2,  3,  4,  5,  6,  8, 10, 11, 12, 13, 14, 15, 17, 18, 19,\n",
            "       20, 21, 22, 24,  0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 12, 13, 14,\n",
            "       15, 16, 17, 18, 19, 20, 21, 22,  0,  1,  2,  4,  5,  6,  7,  8, 10,\n",
            "       11, 12, 13, 14, 15, 16, 18, 19, 22, 24,  0,  2,  3,  4,  6,  8, 10,\n",
            "       13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  4,  5,\n",
            "        6,  7,  8,  9, 10, 13, 15, 16, 17, 19, 21, 22, 23, 24,  2,  3,  4,\n",
            "        6,  7,  8,  9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24,  0,  1,\n",
            "        2,  3,  5,  8,  9, 11, 12, 14, 17, 18, 19, 22, 23, 24,  0,  1,  2,\n",
            "        3,  4,  5,  6,  7,  8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22,\n",
            "       24,  0,  1,  2,  3,  5,  6,  7,  8,  9, 11, 12, 13, 15, 16, 17, 19,\n",
            "       20, 21, 22, 23, 24,  0,  2,  3,  5,  6,  7,  9, 10, 11, 12, 16, 17,\n",
            "       18, 19, 20, 21, 22, 24,  0,  1,  2,  4,  5,  7,  8,  9, 10, 12, 14,\n",
            "       15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,  2,  3,  4,  5,  8,\n",
            "        9, 10, 12, 13, 14, 15, 17, 19, 21, 23, 24,  0,  1,  4,  5,  6,  7,\n",
            "        9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  1,\n",
            "        2,  4,  5,  7,  8,  9, 10, 11, 14, 15, 17, 18, 20, 21, 22,  3,  5,\n",
            "        6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24,  1,\n",
            "        2,  4,  5,  6,  7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 24,  0,  1,\n",
            "        2,  3,  4,  5,  8,  9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24,\n",
            "        0,  1,  2,  4,  8,  9, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23,\n",
            "       24,  0,  1,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "       18, 19, 20, 21, 23, 24,  0,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13,\n",
            "       14, 15, 17, 18, 19, 20, 21, 22, 23,  0,  1,  2,  4,  5,  6,  7,  8,\n",
            "        9, 10, 11, 12, 13, 15, 19, 20, 21, 22,  0,  2,  3,  5,  6,  7,  8,\n",
            "        9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23,  0,  3,  4,\n",
            "        5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24,\n",
            "        0,  1,  2,  3,  4,  6,  7,  8,  9, 11, 16, 17, 18, 19, 20, 21, 22,\n",
            "       23, 24]))\n",
            "prune_low_magnitude_dense_62/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 28 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_62/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 29 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_63/kernel:0 -- Total:150, Zeros: 74.67%\n",
            "i iddex is zero_idx is 30 (array([ 0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,\n",
            "        3,  4,  4,  4,  4,  5,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,\n",
            "        7,  7,  8,  8,  8,  8,  8,  9,  9,  9, 10, 10, 10, 10, 10, 10, 11,\n",
            "       11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 15,\n",
            "       15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 18, 18,\n",
            "       18, 18, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 21, 21, 22,\n",
            "       22, 22, 22, 23, 23, 23, 24, 24, 24, 24]), array([1, 3, 4, 5, 0, 1, 2, 3, 4, 0, 3, 4, 5, 0, 2, 3, 4, 5, 0, 2, 3, 5,\n",
            "       0, 1, 3, 4, 5, 0, 1, 2, 5, 1, 2, 3, 4, 5, 0, 2, 3, 4, 5, 2, 4, 5,\n",
            "       0, 1, 2, 3, 4, 5, 0, 1, 5, 0, 1, 3, 4, 5, 0, 1, 2, 4, 5, 0, 1, 3,\n",
            "       5, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 0, 3, 4, 5, 1,\n",
            "       2, 3, 4, 5, 0, 2, 3, 4, 5, 0, 1, 3, 4, 0, 1, 2, 5, 0, 1, 3, 0, 2,\n",
            "       3, 4]))\n",
            "prune_low_magnitude_dense_63/bias:0 -- Total:6, Zeros: 0.00%\n",
            "i iddex is zero_idx is 31 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_63/mask:0 -- Total:150, Zeros: 74.67%\n",
            "i iddex is zero_idx is 32 (array([ 0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,\n",
            "        3,  4,  4,  4,  4,  5,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,\n",
            "        7,  7,  8,  8,  8,  8,  8,  9,  9,  9, 10, 10, 10, 10, 10, 10, 11,\n",
            "       11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 15,\n",
            "       15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 18, 18,\n",
            "       18, 18, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 21, 21, 22,\n",
            "       22, 22, 22, 23, 23, 23, 24, 24, 24, 24]), array([1, 3, 4, 5, 0, 1, 2, 3, 4, 0, 3, 4, 5, 0, 2, 3, 4, 5, 0, 2, 3, 5,\n",
            "       0, 1, 3, 4, 5, 0, 1, 2, 5, 1, 2, 3, 4, 5, 0, 2, 3, 4, 5, 2, 4, 5,\n",
            "       0, 1, 2, 3, 4, 5, 0, 1, 5, 0, 1, 3, 4, 5, 0, 1, 2, 4, 5, 0, 1, 3,\n",
            "       5, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 0, 3, 4, 5, 1,\n",
            "       2, 3, 4, 5, 0, 2, 3, 4, 5, 0, 1, 3, 4, 0, 1, 2, 5, 0, 1, 3, 0, 2,\n",
            "       3, 4]))\n",
            "prune_low_magnitude_dense_63/threshold:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 33 (array([], dtype=int64),)\n",
            "prune_low_magnitude_dense_63/pruning_step:0 -- Total:1, Zeros: 0.00%\n",
            "i iddex is zero_idx is 34 (array([], dtype=int64),)\n",
            "Edge users are: [25, 7, 6, 4, 14, 24, 22, 19, 26, 27, 9, 18]\n",
            "Central users are: [ 1  2  3  5  8 10 11 12 13 15 16 17 20 21 23 28 29]\n",
            "Writing training logs to /tmp/tmp2qc586_t\n",
            "End step: 1175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4316ddd8838f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0medge_central_ratio\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medge_central_ratio_lst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_runs_per_edge_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcentral_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_prune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprune_at_edge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_at_center\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at_center\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_at_edge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_at_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhar_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhar_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhar_dataset_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhar_dataset_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_central_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_central_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcentral_acc_lst1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentral_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0medge_acc_lst1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-edca091cbf0d>\u001b[0m in \u001b[0;36mrun_prune\u001b[0;34m(prune_at_edge, prune_at_center, train_at_edge, har_dataset, har_dataset_y, sub_map, edge_central_ratio, num_epoches, eval_before_prune)\u001b[0m\n\u001b[1;32m     95\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m            \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m            validation_data=(central_test_x, central_test_y))\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcentral_model_har\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentral_test_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentral_test_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;31m# Callbacks batch_begin.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_begin_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'on_{mode}_batch_begin'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhook_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mtuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruning_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3599\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3600\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3601\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O-opJ8Ihiqn"
      },
      "source": [
        "### Run Pruning experiment with: </br>\n",
        "prune_at_edge=False</br>\n",
        "prune_at_center=True</br>\n",
        "train_at_edge=True</br> \n",
        "Results will be printed to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdyF5a8YRzdt"
      },
      "source": [
        "\n",
        "prune_at_edge=False\n",
        "prune_at_center=True\n",
        "train_at_edge=True\n",
        "\n",
        "central_acc_lst2=[]\n",
        "edge_acc_lst2=[]\n",
        "\n",
        "for edge_central_ratio in edge_central_ratio_lst:\n",
        "  for run in range(num_runs_per_edge_ratio):\n",
        "    central_acc, edge_acc = run_prune(prune_at_edge=prune_at_edge, prune_at_center=prune_at_center, train_at_edge=train_at_edge, har_dataset=har_dataset, har_dataset_y=har_dataset_y, sub_map=sub_map, edge_central_ratio=edge_central_ratio)\n",
        "    central_acc_lst2.append(central_acc)\n",
        "    edge_acc_lst2.append(edge_acc)\n",
        "\n",
        "with open('/content/drive/My Drive/pef_pct_tet_bl_20.txt', 'w') as f:\n",
        "        f.writelines(\"%s\\n\" % central_acc_lst2)\n",
        "        f.writelines(\"%s\\n\" % edge_acc_lst2)   \n",
        "\n",
        "print(\"central_acc_lst is\", central_acc_lst2)\n",
        "print(\"edge_acc_lst is\",edge_acc_lst2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4KhNqquhoiI"
      },
      "source": [
        "### Run Pruning experiment with: </br>\n",
        "prune_at_edge=True</br>\n",
        "prune_at_center=False</br>\n",
        "train_at_edge=True</br> \n",
        "Results will be printed to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee4U90NXSCKD"
      },
      "source": [
        "\n",
        "prune_at_edge=True\n",
        "prune_at_center=False\n",
        "train_at_edge=True\n",
        "\n",
        "central_acc_lst3=[]\n",
        "edge_acc_lst3=[]\n",
        "\n",
        "for edge_central_ratio in edge_central_ratio_lst:\n",
        "  for run in range(num_runs_per_edge_ratio):\n",
        "    central_acc, edge_acc = run_prune(prune_at_edge=prune_at_edge, prune_at_center=prune_at_center, train_at_edge=train_at_edge, har_dataset=har_dataset, har_dataset_y=har_dataset_y, sub_map=sub_map, edge_central_ratio=edge_central_ratio)\n",
        "    central_acc_lst3.append(central_acc)\n",
        "    edge_acc_lst3.append(edge_acc)\n",
        "\n",
        "with open('/content/drive/My Drive/pet_pcf_tet_bl_20.txt', 'w') as f:\n",
        "        f.writelines(\"%s\\n\" % central_acc_lst3)\n",
        "        f.writelines(\"%s\\n\" % edge_acc_lst3)   \n",
        "\n",
        "print(\"central_acc_lst is\", central_acc_lst3)\n",
        "print(\"edge_acc_lst is\",edge_acc_lst3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mQ3UcXCnSuR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEXYOC76nSuT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}