{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAR_Data_Class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPflJeUxgS/DCJZRQqOjh3H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmoranrun/HAR_Dist_ML/blob/main/HAR_Data_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NoteBook containing the HAR_Data Class\n",
        "This Class is used to manipulate the UCI HAR Dataset.\n",
        "(Human activity recognition using smartphones data set. https://archive.ics.uci.edu/ml/machine-learning-databases/00240)\n",
        "\n",
        "Different users/subjects can be assigned to the training and test dataset.\n",
        "The Class constructor takes in the: <br>\n",
        " (1) **har_dataset**  <br>\n",
        "\n",
        "The har_dataset is a 3-D np array of form: [num_of_samples, num_of_timesamples, num_of_feature]\n",
        "\n",
        "Where num_of_samples is the total number of recorded activites \n",
        "                    num_of_timesamples is the total number of timesammples in each recorded activity \n",
        "                   num_of_feature is the total number of features recorded using the smartphones.\n",
        "  This dataset removes the orginal test and training user mapping to samples and we want to redefine this ourselves in various experiments. <br>\n",
        "\n",
        " (2) **y**: a vector containing the classification of each sample <br>\n",
        "\n",
        " (3) **sub_map**: a vector mapping each sample to a particular subject <br>\n",
        "\n",
        " (4) **test_users**: a list containing the subjects assigned to be test users <br>\n",
        "\n",
        "  (5) **train_users**: a list containing the subjects assigned to be train users <br>\n",
        "\n",
        "\n",
        "\n",
        "The method **select_user_val** will allow a percentage of the test users samples to moved into the training dataset,  the percentage amount is controlled with the parameter *percentage_mix*. It's guaranteed that all the test sujects will have some of their samples moved. "
      ],
      "metadata": {
        "id": "FWZbMcDz0g-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random \n",
        "\n",
        "class Har_Data:\n",
        "  def __init__(self, har_dataset, y, sub_map, test_users, train_user):\n",
        "    self.har_dataset = har_dataset\n",
        "    self.y = y\n",
        "    self.sub_map = sub_map\n",
        "    self.test_users = test_users\n",
        "    self.train_user = train_user\n",
        "\n",
        "#######################################################################\n",
        "# Function to move selected test samples to traning dataset\n",
        "# Lots of parameters - however, these are driven by a higher level\n",
        "# function (select_user_val), which has a more user friendly parameter list\n",
        "####################################################################### \n",
        "  def move_test_to_train(self, move_samples, move_sub_map, move_ys, move_idx, har_dataset_user_test, har_submap_user_test, har_dataset_user_train, har_submap_user_train, har_y_user_test, har_y_user_train):\n",
        "    har_dataset_user_test = np.asarray(har_dataset_user_test)\n",
        "    har_submap_user_test = np.asarray(har_submap_user_test)\n",
        "    har_dataset_user_train = np.asarray(har_dataset_user_train)\n",
        "    har_submap_user_train = np.asarray(har_submap_user_train)\n",
        "    har_y_user_test = np.asarray(har_y_user_test)\n",
        "    har_y_user_train = np.asarray(har_y_user_train)\n",
        "    move_samples = np.asarray(move_samples)\n",
        "    move_ys = np.asarray(move_ys)\n",
        "\n",
        "    ## Delete the sample to be moved from the test dataset\n",
        "    har_dataset_user_test = np.delete(har_dataset_user_test, move_idx, axis=0)\n",
        "    har_submap_user_test = np.delete(har_submap_user_test, move_idx, axis=0)\n",
        "    har_y_user_test = np.delete(har_y_user_test, move_idx, axis=0)\n",
        "\n",
        "    ## Add the deleted samples to the trainind dataset\n",
        "    har_dataset_user_train = np.concatenate((har_dataset_user_train, move_samples))\n",
        "    har_submap_user_train = np.concatenate((har_submap_user_train, move_sub_map))\n",
        "    har_y_user_train = np.concatenate((har_y_user_train, move_ys))\n",
        "    return  har_dataset_user_test, har_submap_user_test, har_y_user_test, har_dataset_user_train, har_submap_user_train, har_y_user_train\n",
        "\n",
        "#############################################################################################\n",
        "# Function to create a user dataset\n",
        "# har_dataset is a 3-D np array of form: [num_of_samples, num_of_timesamples, num_of_feature]\n",
        "#             Where num_of_samples is the total number of recorded activites \n",
        "#                   num_of_timesamples is the total number of timesammples in each recorded activity \n",
        "#                   num_of_feature is the total number of features recorded using the smartphones.\n",
        "# sub_map maps subjects (people) to each har_dataset sample\n",
        "# test_user lists which subjects are assigned to the test dataset\n",
        "# train_user lists which subjects are assigned to the training dataset\n",
        "# percent_mix determines the percentage of the test dataset samples to move into the training dataset\n",
        "#############################################################################################\n",
        "  def select_user_val(self, percent_mix):\n",
        "    har_dataset_user_test=[]\n",
        "    har_submap_user_test=[]\n",
        "    har_y_user_test=[]\n",
        "    for user in self.test_users:\n",
        "      har_dataset_user_test.extend(self.har_dataset[tuple(np.where(self.sub_map==user))].tolist()) \n",
        "      har_submap_user_test.extend(self.sub_map[np.where(self.sub_map==user)].tolist())\n",
        "      har_y_user_test.extend(self.y[tuple(np.where(self.sub_map==user))].tolist()) \n",
        "    # Generate the default training dataset \n",
        "    har_dataset_user_train=[]\n",
        "    har_submap_user_train=[]\n",
        "    har_y_user_train=[]\n",
        "    for user in self.train_user:\n",
        "      har_dataset_user_train.extend(self.har_dataset[tuple(np.where(self.sub_map==user))].tolist())\n",
        "      har_submap_user_train.extend(self.sub_map[np.where(self.sub_map==user)].tolist())\n",
        "      har_y_user_train.extend(self.y[tuple(np.where(self.sub_map==user))].tolist()) \n",
        " \n",
        "  ## Now allow a percentage of test users samples to enter the training dataset\n",
        "  ## Make sure that the percentage comes from each test user\n",
        "    for user in self.test_users:\n",
        "      har_user_sub_map=np.where(np.asarray(har_submap_user_test)==user)[0]\n",
        "      har_user_sub_map_cnt=np.count_nonzero(np.asarray(har_submap_user_test)==user)\n",
        "      num_take_sub_map = int(har_user_sub_map_cnt*percent_mix)\n",
        "      if(num_take_sub_map > 0) :\n",
        "        move_idx=random.sample(list(har_user_sub_map), num_take_sub_map)\n",
        "        move_samples=[har_dataset_user_test[i] for i in move_idx]  \n",
        "        move_sub_map=[har_submap_user_test[i] for i in move_idx]   \n",
        "        move_ys=[har_y_user_test[i] for i in move_idx]   \n",
        "        har_dataset_user_test, har_submap_user_test, har_y_user_test, har_dataset_user_train, har_submap_user_train, har_y_user_train \\\n",
        "          = self.move_test_to_train(move_samples, move_sub_map, move_ys, move_idx, har_dataset_user_test, har_submap_user_test, har_dataset_user_train, har_submap_user_train, har_y_user_test, har_y_user_train)\n",
        "    return  np.asarray(har_dataset_user_test), np.asarray(har_submap_user_test), np.asarray(har_y_user_test), np.asarray(har_dataset_user_train), np.asarray(har_submap_user_train), np.asarray(har_y_user_train)\n",
        " "
      ],
      "metadata": {
        "id": "LbLBV1KL0dsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}